7767517
51 50
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,480,320)f32
nn.Conv2d                convbn2d_0               1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,3,3,3)f32 $input=0 #0=(1,3,480,320)f32 #1=(1,64,480,320)f32
nn.ReLU                  inc.double_conv.2        1 1 1 2 #1=(1,64,480,320)f32 #2=(1,64,480,320)f32
nn.Conv2d                convbn2d_1               1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 $input=2 #2=(1,64,480,320)f32 #3=(1,64,480,320)f32
nn.ReLU                  inc.double_conv.5        1 1 3 4 #3=(1,64,480,320)f32 #4=(1,64,480,320)f32
nn.MaxPool2d             down1.maxpool_conv.0     1 1 4 5 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #4=(1,64,480,320)f32 #5=(1,64,240,160)f32
nn.Conv2d                convbn2d_2               1 1 5 6 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,64,3,3)f32 $input=5 #5=(1,64,240,160)f32 #6=(1,128,240,160)f32
nn.ReLU                  down1.maxpool_conv.1.double_conv.2 1 1 6 7 #6=(1,128,240,160)f32 #7=(1,128,240,160)f32
nn.Conv2d                convbn2d_3               1 1 7 8 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 $input=7 #7=(1,128,240,160)f32 #8=(1,128,240,160)f32
nn.ReLU                  down1.maxpool_conv.1.double_conv.5 1 1 8 9 #8=(1,128,240,160)f32 #9=(1,128,240,160)f32
nn.MaxPool2d             down2.maxpool_conv.0     1 1 9 10 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #9=(1,128,240,160)f32 #10=(1,128,120,80)f32
nn.Conv2d                convbn2d_4               1 1 10 11 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,3,3)f32 $input=10 #10=(1,128,120,80)f32 #11=(1,256,120,80)f32
nn.ReLU                  down2.maxpool_conv.1.double_conv.2 1 1 11 12 #11=(1,256,120,80)f32 #12=(1,256,120,80)f32
nn.Conv2d                convbn2d_5               1 1 12 13 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 $input=12 #12=(1,256,120,80)f32 #13=(1,256,120,80)f32
nn.ReLU                  down2.maxpool_conv.1.double_conv.5 1 1 13 14 #13=(1,256,120,80)f32 #14=(1,256,120,80)f32
nn.MaxPool2d             down3.maxpool_conv.0     1 1 14 15 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #14=(1,256,120,80)f32 #15=(1,256,60,40)f32
nn.Conv2d                convbn2d_6               1 1 15 16 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,256,3,3)f32 $input=15 #15=(1,256,60,40)f32 #16=(1,512,60,40)f32
nn.ReLU                  down3.maxpool_conv.1.double_conv.2 1 1 16 17 #16=(1,512,60,40)f32 #17=(1,512,60,40)f32
nn.Conv2d                convbn2d_7               1 1 17 18 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,3,3)f32 $input=17 #17=(1,512,60,40)f32 #18=(1,512,60,40)f32
nn.ReLU                  down3.maxpool_conv.1.double_conv.5 1 1 18 19 #18=(1,512,60,40)f32 #19=(1,512,60,40)f32
nn.MaxPool2d             down4.maxpool_conv.0     1 1 19 20 ceil_mode=False dilation=(1,1) kernel_size=(2,2) padding=(0,0) return_indices=False stride=(2,2) #19=(1,512,60,40)f32 #20=(1,512,30,20)f32
nn.Conv2d                convbn2d_8               1 1 20 21 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,3,3)f32 $input=20 #20=(1,512,30,20)f32 #21=(1,512,30,20)f32
nn.ReLU                  down4.maxpool_conv.1.double_conv.2 1 1 21 22 #21=(1,512,30,20)f32 #22=(1,512,30,20)f32
nn.Conv2d                convbn2d_9               1 1 22 23 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=512 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(512)f32 @weight=(512,512,3,3)f32 $input=22 #22=(1,512,30,20)f32 #23=(1,512,30,20)f32
nn.ReLU                  down4.maxpool_conv.1.double_conv.5 1 1 23 24 #23=(1,512,30,20)f32 #24=(1,512,30,20)f32
nn.Upsample              up1.up                   1 1 24 25 align_corners=True mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #24=(1,512,30,20)f32 #25=(1,512,60,40)f32
torch.cat                torch.cat_0              2 1 19 25 26 dim=1 #19=(1,512,60,40)f32 #25=(1,512,60,40)f32 #26=(1,1024,60,40)f32
nn.Conv2d                convbn2d_10              1 1 26 27 bias=True dilation=(1,1) groups=1 in_channels=1024 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1024,3,3)f32 $input=26 #26=(1,1024,60,40)f32 #27=(1,256,60,40)f32
nn.ReLU                  up1.conv.double_conv.2   1 1 27 28 #27=(1,256,60,40)f32 #28=(1,256,60,40)f32
nn.Conv2d                convbn2d_11              1 1 28 29 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,3,3)f32 $input=28 #28=(1,256,60,40)f32 #29=(1,256,60,40)f32
nn.ReLU                  up1.conv.double_conv.5   1 1 29 30 #29=(1,256,60,40)f32 #30=(1,256,60,40)f32
nn.Upsample              up2.up                   1 1 30 31 align_corners=True mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #30=(1,256,60,40)f32 #31=(1,256,120,80)f32
torch.cat                torch.cat_1              2 1 14 31 32 dim=1 #14=(1,256,120,80)f32 #31=(1,256,120,80)f32 #32=(1,512,120,80)f32
nn.Conv2d                convbn2d_12              1 1 32 33 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,512,3,3)f32 $input=32 #32=(1,512,120,80)f32 #33=(1,128,120,80)f32
nn.ReLU                  up2.conv.double_conv.2   1 1 33 34 #33=(1,128,120,80)f32 #34=(1,128,120,80)f32
nn.Conv2d                convbn2d_13              1 1 34 35 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 $input=34 #34=(1,128,120,80)f32 #35=(1,128,120,80)f32
nn.ReLU                  up2.conv.double_conv.5   1 1 35 36 #35=(1,128,120,80)f32 #36=(1,128,120,80)f32
nn.Upsample              up3.up                   1 1 36 37 align_corners=True mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #36=(1,128,120,80)f32 #37=(1,128,240,160)f32
torch.cat                torch.cat_2              2 1 9 37 38 dim=1 #9=(1,128,240,160)f32 #37=(1,128,240,160)f32 #38=(1,256,240,160)f32
nn.Conv2d                convbn2d_14              1 1 38 39 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,3,3)f32 $input=38 #38=(1,256,240,160)f32 #39=(1,64,240,160)f32
nn.ReLU                  up3.conv.double_conv.2   1 1 39 40 #39=(1,64,240,160)f32 #40=(1,64,240,160)f32
nn.Conv2d                convbn2d_15              1 1 40 41 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 $input=40 #40=(1,64,240,160)f32 #41=(1,64,240,160)f32
nn.ReLU                  up3.conv.double_conv.5   1 1 41 42 #41=(1,64,240,160)f32 #42=(1,64,240,160)f32
nn.Upsample              up4.up                   1 1 42 43 align_corners=True mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #42=(1,64,240,160)f32 #43=(1,64,480,320)f32
torch.cat                torch.cat_3              2 1 4 43 44 dim=1 #4=(1,64,480,320)f32 #43=(1,64,480,320)f32 #44=(1,128,480,320)f32
nn.Conv2d                convbn2d_16              1 1 44 45 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,3,3)f32 $input=44 #44=(1,128,480,320)f32 #45=(1,64,480,320)f32
nn.ReLU                  up4.conv.double_conv.2   1 1 45 46 #45=(1,64,480,320)f32 #46=(1,64,480,320)f32
nn.Conv2d                convbn2d_17              1 1 46 47 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 $input=46 #46=(1,64,480,320)f32 #47=(1,64,480,320)f32
nn.ReLU                  up4.conv.double_conv.5   1 1 47 48 #47=(1,64,480,320)f32 #48=(1,64,480,320)f32
nn.Conv2d                outc.conv                1 1 48 49 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=1 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(1)f32 @weight=(1,64,1,1)f32 #48=(1,64,480,320)f32 #49=(1,1,480,320)f32
pnnx.Output              pnnx_output_0            1 0 49 #49=(1,1,480,320)f32
